# Math 365 / Comp 365: 
# Activity on Bisection Method

### Objectives
- Code the bisection method to find roots
- Understand methods to determine convergence rate

### Question 1

Implement an R function for the bisection method to find a root in a closed interval of a continuous function of one variable. See also the pseudocode in the slides.

Here is an outline for your function:
```{r}
bisect = function(f,interval,tol=0.5*10^-10,max.its=40,verbose=FALSE){
  history = rep(NA, max.its)
  a = interval[1]
  b = interval[2]
  fa = f(a)
  fb = f(b)
  if (sign(fa)*sign(fb) >= 0 ) 
    stop("f(a)f(b)<0 not satisfied")
  for (j in 1:max.its){
    history[j] = (a+b)/2
    if ((b-a)/2 < tol) break
    fc = f(history[j])
    if (verbose==TRUE) {               # show values at each step for debugging
      print(j) 
      print(c(a,history[j],b,b-a))
    }
    if (fc == 0)  break
    if (sign(fc)*sign(fa) < 0) {
      b = history[j]
      fb = fc
    }
    else {
      a = history[j]
      fa = fc
    }
  }
  root=(a+b)/2
  return(list(root=root,history=history[!is.na(history)]))
}
```

In the first line of the function definition, we set default values for the variables `tol` and `max.its`. That is, the user has the option to enter values for these variables when calling the function, but if they do not enter any values, then the values after the equals signs will be used instead. We stop the procedure when either (i)  the length of the bracket window is below the tolerance or (ii) the maximum number of iterations has been reached.

The variable `history` will track all of the iterative estimates of the root. We initialize it in order to preallocate memory, which speeds up the program.

We want the function to return two variables: the final estimate of the root and the history of all of the intermediate estimates. One way to do this in R is to return a list of variables. Note also that we can shorten the history vector to however many iterations we actually computed (instead of including all of those NAs).

Don't forget to carefully comment your function!

To use our function, we would define a function $f$ and an interval, and then call
```{r}
f = function(x){x^2-16}
interval = c(0,10)
tol = 0.5e-5
out=bisect(f,interval,tol)
out
```
Here, the dollar sign is a way to access each individual item in the list.


### Question 2

Test your function by running at most 40 iterations of the bisection method on the function $f(x)=x^4-\frac{1}{81}$, with a starting bracket interval of $[0,1]$ and a tolerance of 0.5*10^-10. Then compute the vector of error ratios
$$ \left[\frac{e_1}{e_0},\frac{e_2}{e_1},\ldots\right] $$
to confirm that the algorithm is converging linearly. Then, change the vector of error ratios to
$$ \left[\frac{e_1}{(e_0)^2},\frac{e_2}{(e_1)^2},\ldots\right] $$ to see that the Bisection Method does not converge quadratically.

```{r}
f = function(x){
  return(x^4-1/81)
}
interval <- c(0,1)
out=bisect(f,interval)
print(out$root)
print(out$history)
```

```{r}
(errors=abs(out$history-1/3))
n=length(errors)
(ratios=errors[2:n]/(errors[1:(n-1)]^1))
```
We can see that if we test for quadratic convergence with q=2, the ratios diverge because the error is not decaying fast enough. So it does not converge quadratically, which is what we expect from theoretical analysis of the bisection method.
```{r}
(quad.ratios=errors[2:n]/(errors[1:(n-1)]^2))
```



### Question 3

In the previous problem, we looked at successive ratios of the errors to see if they converge to a number. Another method to determine the convergence order is to plot the log-log plot of the error data, i.e. plot $(\log e_i, \log e_{i+1})$. To see why, consider: 

a. Turn the equation $e_{i_1}=Ce_i^q$ into a straight line by taking the log of both sides and manipulating the equation to look like $y=mx+b$.

b. What do you notice about the slope of the straight line?

c. Now, test that the previous problem had linear convergence by plotting the log-log plot of the error data $(\log e_i, \log e_{i+1})$ and observing what the slope is.
